
# PredicciÃ³n de PrÃ©stamos Digitales en Clientes Peruanos ğŸ‡µğŸ‡ª

Este proyecto tiene como objetivo aplicar tÃ©cnicas de regresiÃ³n lineal y redes neuronales para predecir el monto de prÃ©stamos digitales de clientes peruanos, utilizando Python y herramientas de ciencia de datos.

## ğŸ¯ Objetivo General

Aplicar tÃ©cnicas de regresiÃ³n lineal y redes neuronales artificiales para predecir el monto de prÃ©stamos digitales.

## âœ… Objetivos EspecÃ­ficos

- Implementar un modelo de regresiÃ³n lineal simple.
- Desarrollar una red neuronal para predecir montos basÃ¡ndose en mÃºltiples variables.
- Manipular datos con Pandas y NumPy.
- Visualizar resultados con Matplotlib.
- Aplicar estructuras de programaciÃ³n en Python.
- Usar GitHub como sistema de control de versiones.

## ğŸ“ Dataset

- Fuente: Kaggle - PrÃ©stamos Digitales - PerÃº
- Variables comunes:
  - `cliente`, `genero`, `procedencia`, `trxDigitalUm`, `promSaldoBanco3Um`, `ventaPrestDig`, entre otras.

âœ… Variables disponibles
Variable	          DescripciÃ³n
mes	                AÃ±o y mes en formato yyyymm
cliente	            ID del cliente
estadoCliente	      Estado del cliente (A, B, etc.)
rngEdad	            Rango de edad (ej: <35-45])
genero	            M o F
rngSueldo	          Rango de sueldo
procedencia	        Ciudad (ej: lima)
operDigital	        Estado de operaciÃ³n digital (NN, etc.)
trxDigitalUm	      NÃºmero de transacciones digitales
promTrxDig3Um	      Promedio de transacciones digitales
recCamp	            ParticipaciÃ³n en campaÃ±a (0/1)
frecCamp	          Frecuencia en campaÃ±as
tenTarjeta	        Tipo de tarjeta (ej: TC-TD)
promConsBanco3Um  	Promedio consumo banco 3 Ãºltimos meses
promSaldoBanco3Um	  Promedio saldo banco 3 Ãºltimos meses
promSaldoTc3Um    	Promedio saldo tarjeta 3 Ãºltimos meses
promSaldoPrest3Um 	Promedio saldo prÃ©stamo 3 Ãºltimos meses
sowTcUm           	ParticipaciÃ³n tarjeta
sowPrestUm	        ParticipaciÃ³n prÃ©stamo
ventaPrestDig	      Monto del prÃ©stamo digital (target)

## ğŸ§ª LibrerÃ­as Utilizadas

- pandas
- numpy
- matplotlib
- scikit-learn
- tensorflow / keras

## ğŸ”¢ Modelos Implementados

  RegresiÃ³n Lineal Simple

  Red Neuronal (Keras)



## ğŸ“Š Visualizaciones

- GrÃ¡fico de regresiÃ³n lineal.
- EvoluciÃ³n del error de entrenamiento de la red neuronal (Loss vs Epochs).
- ComparaciÃ³n entre valores reales y predichos.

## ğŸ” LÃ³gica de ProgramaciÃ³n

El proyecto incluye:
- Uso de bucles (`for`)
- Condicionales (`if`)
- Diccionarios y listas para anÃ¡lisis personalizados



## ğŸ“Œ Conclusiones

- La regresiÃ³n lineal mostrÃ³ una tendencia, aunque limitada, de correlaciÃ³n.
- La red neuronal logrÃ³ mejores resultados ajustando mÃºltiples variables.
- Las tÃ©cnicas de Machine Learning son Ãºtiles para entender el comportamiento de prÃ©stamos digitales.

## ğŸš€ CÃ³mo Ejecutar

1. Abre el notebook en Google Colab.
2. Sube el archivo `dataBasePrestDigital.csv` al entorno.
3. Ejecuta todas las celdas paso a paso.

## ğŸ”— Respuesta a las preguntas 

Pregunta 1 

Â¿QuÃ© criterio utilizaste para seleccionar la variable independiente en la regresiÃ³n lineal simple? Â¿Por quÃ© crees que esa variable influye en el monto del prÃ©stamo?

Para el experimento de regresiÃ³n lineal simple que analizamos en detalle con su grÃ¡fico y mÃ©tricas, la variable independiente seleccionada fue promSaldoBanco3Um . La decisiÃ³n de usar esta variable se tomÃ³ como parte de la exploraciÃ³n para entender cÃ³mo diferentes caracterÃ­sticas individuales se relacionaban linealmente con el monto del prÃ©stamo (promSaldoPrest3Um) en los datos filtrados (donde el monto del prÃ©stamo era mayor a cero).

Â¿Por quÃ© se podrÃ­a pensar que promSaldoBanco3Um influye en el monto del prÃ©stamo?
La hipÃ³tesis serÃ­a que el saldo promedio que una persona maneja en sus cuentas bancarias podrÃ­a ser un indicador de su comportamiento financiero general, su capacidad de endeudamiento o su propensiÃ³n a utilizar otros productos crediticios.

Pregunta 2:
Â¿QuÃ© significa el error MSE (Mean Squared Error) y quÃ© te indica sobre el rendimiento del modelo?

El MSE (Error CuadrÃ¡tico Medio) es una mÃ©trica que se usa para medir el rendimiento de un modelo de regresiÃ³n. Se calcula asÃ­:

Para cada predicciÃ³n, se toma la diferencia entre el valor real y el valor predicho.
Esta diferencia (el error) se eleva al cuadrado.
Se suman todos estos errores al cuadrado.
Finalmente, se calcula el promedio de esta suma.

Â¿QuÃ© indica sobre el rendimiento del modelo?

El MSE te da una medida de la magnitud promedio de los errores al cuadrado.
Al elevar los errores al cuadrado, el MSE penaliza de forma mÃ¡s significativa los errores grandes. Por ejemplo, un error de 10 unidades contribuye con 100 al MSE, mientras que un error de 2 unidades solo contribuye con 4.
Un valor de MSE mÃ¡s bajo indica un mejor rendimiento del modelo, ya que significa que, en promedio, las predicciones del modelo estÃ¡n mÃ¡s cerca de los valores reales.
La unidad del MSE es la unidad de la variable objetivo al cuadrado. Por esto, a veces se prefiere usar la raÃ­z cuadrada del MSE (RMSE), que estÃ¡ en la misma unidad que la variable objetivo y es mÃ¡s fÃ¡cil de interpretar directamente.

Pregunta 3:
Â¿QuÃ© conclusiones sacaste al comparar los valores predichos por el modelo con los valores reales? Â¿Hubo sobreajuste o subajuste? Â¿CÃ³mo lo detectaste?

Al comparar los valores predichos con los reales, tanto para la regresiÃ³n lineal simple como para la red neuronal (con las 3 variables seleccionadas), las conclusiones fueron:

RegresiÃ³n Lineal Simple (con promSaldoBanco3Um):

El R2 fue extremadamente bajo (0.02).
El grÃ¡fico de "Valores Reales vs. PredicciÃ³n" mostrÃ³ una lÃ­nea de regresiÃ³n casi horizontal, indicando que el modelo predecÃ­a valores muy similares independientemente del valor real del saldo de la ceunta bancaria.
Esto indica un claro subajuste (underfitting). El modelo era demasiado simple (una lÃ­nea recta con una sola variable dÃ©bilmente correlacionada) para capturar la complejidad de los datos y no aprendÃ­a bien ni siquiera de los datos de entrenamiento.
Red Neuronal (con 3 variables):

El grÃ¡fico de "EvoluciÃ³n del Error (MAE) Durante el Entrenamiento" mostrÃ³ que las curvas de error de entrenamiento y de validaciÃ³n disminuyeron y luego se estabilizaron en un nivel de MAE relativamente alto (alrededor de 6950-7195).
El grÃ¡fico de "Valores Reales vs. Predicciones" mostrÃ³ que, aunque habÃ­a mÃ¡s variabilidad en las predicciones que con la regresiÃ³n lineal, los puntos seguÃ­an muy dispersos de la lÃ­nea de "predicciÃ³n perfecta", y el modelo tendÃ­a a subestimar severamente los montos de prÃ©stamo mÃ¡s grandes.
El R2 final de la red neuronal tambiÃ©n fue bajo

DetecciÃ³n:

Principalmente subajuste: El MAE alto y el R2 bajo en el conjunto de prueba, junto con curvas de aprendizaje que se estabilizan en un error alto, sugieren que el modelo, a pesar de ser mÃ¡s complejo, seguÃ­a subajustando. Las 3 variables seleccionadas no parecÃ­an tener suficiente poder predictivo para explicar la variabilidad del monto del prÃ©stamo.
No hubo evidencia clara de sobreajuste (overfitting) significativo, ya que la curva de error de validaciÃ³n no empezÃ³ a aumentar drÃ¡sticamente mientras la de entrenamiento continuaba bajando. Ambas se estabilizaron juntas, aunque en un nivel de error no ideal.

Â¿QuÃ© desafÃ­os encontraste al trabajar con el dataset y cÃ³mo los solucionaste (por ejemplo, valores faltantes, codificaciÃ³n de categorÃ­as, etc.)?

Durante el trabajo con el dataset, enfrentamos varios desafÃ­os comunes en el preprocesamiento de datos:

Valores Faltantes (NaN):

DesafÃ­o: PodrÃ­an haber existido despuÃ©s del mapeo de rangos o en otras columnas. Los modelos no pueden procesar NaN.
SoluciÃ³n: Para rngEdad y rngSueldo, despuÃ©s de mapearlos, rellenamos los NaN con la mediana de los valores ya convertidos, lo cual es robusto a valores atÃ­picos. Al final del preprocesamiento general, aplicamos df_processed.fillna(0) para rellenar cualquier NaN restante en el DataFrame con ceros, una estrategia simple para asegurar que no haya faltantes.

CodificaciÃ³n de Variables CategÃ³ricas:

DesafÃ­o: Variables como rngEdad, rngSueldo (inicialmente texto), genero, estadoCliente, procedencia, operDigital, y tenTarjeta necesitaban ser convertidas a un formato numÃ©rico para los modelos.
SoluciÃ³n:
Mapeo Manual: Para rngEdad y rngSueldo, usamos diccionarios para asignar valores numÃ©ricos especÃ­ficos a cada rango.
ConversiÃ³n Binaria: Para genero, usamos una funciÃ³n lambda para convertir 'M' a 1 y 'F' a 0.
One-Hot Encoding: Para las demÃ¡s variables categÃ³ricas nominales (estadoCliente, procedencia, operDigital, tenTarjeta), utilizamos pd.get_dummies() con drop_first=True para crear nuevas columnas binarias para cada categorÃ­a, evitando la trampa de la multicolinealidad.

Luego, convertimos las columnas booleanas resultantes del One-Hot Encoding a enteros (0 y 1).
Alta ProporciÃ³n de Ceros en la Variable Objetivo (promSaldoPrest3Um):

DesafÃ­o: Ya que un alto porcentaje de la variable objetivo eran ceros, lo cual podÃ­a sesgar el modelo de regresiÃ³n y dificultar la predicciÃ³n de los montos no nulos.
SoluciÃ³n: Adoptamos la estrategia de filtrar los datos, creando un nuevo DataFrame df_no_cero que contenÃ­a solo las filas donde promSaldoPrest3Um > 0. Esto permitiÃ³ que los modelos se enfocaran en predecir el monto cuando este efectivamente existÃ­a.
Escalado de CaracterÃ­sticas para la Red Neuronal:

DesafÃ­o: Las redes neuronales funcionan mejor cuando las caracterÃ­sticas de entrada estÃ¡n en una escala similar.

SoluciÃ³n: Utilizamos StandardScaler de Scikit-learn para escalar las 3 variables seleccionadas (rngSueldo, promSaldoTc3Um, promConsBanco3Um) antes de entrenar la red neuronal.
## ğŸ”— Repositorio
https://colab.research.google.com/drive/1qa2BZVXS6xe5kGl0nAFHZv9O60-hKmz5?usp=sharing

